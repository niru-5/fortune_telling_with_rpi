{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/resources/mm_env/lib/python3.10/site-packages/mmengine/optim/optimizer/zero_optimizer.py:11: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
      "  from torch.distributed.optim import \\\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import logging\n",
    "from argparse import ArgumentParser\n",
    "import sys\n",
    "sys.path.append('/mnt/c/Users/niran/Documents/personal_work/fun_projects/fortune_telling_with_rpi/py_env/lib/python3.10/site-packages')\n",
    "sys.path.append('/home/friday/fortune_telling_with_rpi/mmpose')\n",
    "from mmcv.image import imread\n",
    "from mmengine.logging import print_log\n",
    "\n",
    "from mmpose.apis import inference_topdown, init_model\n",
    "from mmpose.registry import VISUALIZERS\n",
    "from mmpose.structures import merge_data_samples\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/friday/fortune_telling_with_rpi/data/rpi_data/images/image_9.jpeg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 97\u001b[0m\n\u001b[1;32m     82\u001b[0m     visualizer\u001b[38;5;241m.\u001b[39mset_dataset_meta(\n\u001b[1;32m     83\u001b[0m     model\u001b[38;5;241m.\u001b[39mdataset_meta, skeleton_style\u001b[38;5;241m=\u001b[39mskeleton_style)\n\u001b[1;32m     84\u001b[0m     visualizer\u001b[38;5;241m.\u001b[39madd_datasample(\n\u001b[1;32m     85\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     86\u001b[0m         img_path,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     94\u001b[0m         show\u001b[38;5;241m=\u001b[39mshow,\n\u001b[1;32m     95\u001b[0m         out_file\u001b[38;5;241m=\u001b[39mout_file)\n\u001b[0;32m---> 97\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannel_order\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrgb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m model \u001b[38;5;241m=\u001b[39m model_building(config_path, checkpoint)\n\u001b[1;32m     99\u001b[0m results \u001b[38;5;241m=\u001b[39m inference_model(model, img_path)\n",
      "File \u001b[0;32m/resources/mm_env/lib/python3.10/site-packages/mmcv/image/io.py:225\u001b[0m, in \u001b[0;36mimread\u001b[0;34m(img_or_path, flag, channel_order, backend, file_client_args, backend_args)\u001b[0m\n\u001b[1;32m    223\u001b[0m         img_bytes \u001b[38;5;241m=\u001b[39m file_client\u001b[38;5;241m.\u001b[39mget(img_or_path)\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 225\u001b[0m         img_bytes \u001b[38;5;241m=\u001b[39m \u001b[43mfileio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbackend_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m imfrombytes(img_bytes, flag, channel_order, backend)\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/resources/mm_env/lib/python3.10/site-packages/mmengine/fileio/io.py:181\u001b[0m, in \u001b[0;36mget\u001b[0;34m(filepath, backend_args)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Read bytes from a given ``filepath`` with 'rb' mode.\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \n\u001b[1;32m    166\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;124;03m    b'hello world'\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    179\u001b[0m backend \u001b[38;5;241m=\u001b[39m get_file_backend(\n\u001b[1;32m    180\u001b[0m     filepath, backend_args\u001b[38;5;241m=\u001b[39mbackend_args, enable_singleton\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 181\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/resources/mm_env/lib/python3.10/site-packages/mmengine/fileio/backends/local_backend.py:33\u001b[0m, in \u001b[0;36mLocalBackend.get\u001b[0;34m(self, filepath)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, filepath: Union[\u001b[38;5;28mstr\u001b[39m, Path]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbytes\u001b[39m:\n\u001b[1;32m     19\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Read bytes from a given ``filepath`` with 'rb' mode.\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \n\u001b[1;32m     21\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;03m        b'hello world'\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     34\u001b[0m         value \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m value\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/friday/fortune_telling_with_rpi/data/rpi_data/images/image_9.jpeg'"
     ]
    }
   ],
   "source": [
    "# params\n",
    "config_path = '/home/friday/fortune_telling_with_rpi/mmpose/configs/hand_2d_keypoint/rtmpose/hand5/rtmpose-m_8xb256-210e_hand5-256x256.py'\n",
    "checkpoint = \"/home/friday/fortune_telling_with_rpi/data/models/rtmpose-m_simcc-hand5_pt-aic-coco_210e-256x256-74fb594_20230320.pth\"\n",
    "# rtmpose-m_simcc-coco-wholebody-hand_pt-aic-coco_210e-256x256-99477206_20230228.pth\"\n",
    "\n",
    "thickness = 1\n",
    "radius = 3\n",
    "alpha = 0.8\n",
    "skeleton_style = 'mmpose'\n",
    "kpt_thr = 0.3\n",
    "draw_heatmap = False\n",
    "show_kpt_idx = False\n",
    "show = False\n",
    "out_file = \"./test.bmp\"\n",
    "\n",
    "img_path = \"/home/friday/fortune_telling_with_rpi/data/rpi_data/images/image_9.jpeg\"\n",
    "\n",
    "\n",
    "def model_building(config_path: str, checkpoint: str):\n",
    "    model = init_model(\n",
    "        config_path,\n",
    "        checkpoint,\n",
    "        device='cpu')\n",
    "\n",
    "    model.cfg.visualizer.radius = radius\n",
    "    model.cfg.visualizer.alpha = alpha\n",
    "    model.cfg.visualizer.line_width = thickness\n",
    "    return model\n",
    "\n",
    "\n",
    "def inference_model(model, img_path: str):\n",
    "    batch_results = inference_topdown(model, img_path)\n",
    "    results = merge_data_samples(batch_results)\n",
    "    return results\n",
    "\n",
    "def get_palm_img(results, img):\n",
    "    # the points are\n",
    "    # 0 -> wrist\n",
    "    # 1 -> thumb1\n",
    "    # 5 -> forefinger1\n",
    "    # 9 -> middlefinger1\n",
    "    # 13 -> ringfinger1\n",
    "    # 17 -> pinky1\n",
    "    key_points_detected = results.pred_instances.keypoints[0]\n",
    "    points_to_select = [0, 1, 5, 9, 13, 17]\n",
    "    # Extract points for contour\n",
    "    selected_points = key_points_detected[points_to_select]\n",
    "    # Convert points to integer coordinates for contour\n",
    "    contour_points = selected_points.astype(np.int32)\n",
    "    \n",
    "    # Create mask from contour\n",
    "    mask = np.zeros(img.shape[:2], dtype=np.uint8)\n",
    "    cv2.fillPoly(mask, [contour_points], 255)\n",
    "\n",
    "    # Apply mask to image\n",
    "    masked_img = cv2.bitwise_and(img, img, mask=mask)\n",
    "    \n",
    "    # Get bounding box of contour\n",
    "    x,y,w,h = cv2.boundingRect(contour_points)\n",
    "\n",
    "    # Crop image to bounding box\n",
    "    cropped = masked_img[y:y+h, x:x+w]\n",
    "\n",
    "    # Resize to 256x256\n",
    "    resized = cv2.resize(cropped, (512, 512))\n",
    "    \n",
    "    b, g, r = cv2.split(resized)\n",
    "    b = cv2.equalizeHist(b)\n",
    "    b = cv2.GaussianBlur(b, (5,5), 0)\n",
    "    g = cv2.equalizeHist(g)\n",
    "    g = cv2.GaussianBlur(g, (5,5), 0)\n",
    "    r = cv2.equalizeHist(r)\n",
    "    r = cv2.GaussianBlur(r, (5,5), 0)\n",
    "    # Merge channels back together\n",
    "    resized = cv2.merge((b, g, r))\n",
    "    \n",
    "    \n",
    "    return resized\n",
    "\n",
    "def show_pose_prediction(results, img_path, model, out_file: str):\n",
    "    visualizer = VISUALIZERS.build(model.cfg.visualizer)\n",
    "    visualizer.set_dataset_meta(\n",
    "    model.dataset_meta, skeleton_style=skeleton_style)\n",
    "    visualizer.add_datasample(\n",
    "        'result',\n",
    "        img_path,\n",
    "        data_sample=results,\n",
    "        draw_gt=False,\n",
    "        draw_bbox=True,\n",
    "        kpt_thr=kpt_thr,\n",
    "        draw_heatmap=draw_heatmap,\n",
    "        show_kpt_idx=show_kpt_idx,\n",
    "        skeleton_style=skeleton_style,\n",
    "        show=show,\n",
    "        out_file=out_file)\n",
    "\n",
    "img = imread(img_path, channel_order='rgb')\n",
    "model = model_building(config_path, checkpoint)\n",
    "results = inference_model(model, img_path)\n",
    "palm_img = get_palm_img(results, img)\n",
    "plt.imshow(palm_img)\n",
    "# show_pose_prediction(results, img, model, out_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
